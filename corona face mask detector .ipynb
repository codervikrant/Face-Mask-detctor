{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D,Dropout,Flatten,Dense,Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize the  number of epochs to train for,\n",
    "# and batch size\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"loading images...\")\n",
    "imagePaths = list(paths.list_images(\"dataset\"))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "    # extract the class label from the filename\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "    # load the input image (150x150) and preprocess it\n",
    "    image = load_img(imagePath, target_size=(150, 150))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "# convert the data and labels to NumPy arrays\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.20, stratify=labels, random_state=42)\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 148, 148, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 148, 148, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                4147250   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 4,186,072\n",
      "Trainable params: 4,186,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(128,(3,3),input_shape=(150,150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "#Flatten layer to stack the output convolutions from second convolution layer\n",
    "model.add(Dense(50,activation='relu'))\n",
    "#Dense layer of 64 neurons\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "#The Final layer with two outputs for two categories\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 880 samples, validate on 220 samples\n",
      "Epoch 1/20\n",
      "880/880 [==============================] - 72s 82ms/step - loss: 0.7252 - accuracy: 0.7023 - val_loss: 0.3304 - val_accuracy: 0.8818\n",
      "Epoch 2/20\n",
      "880/880 [==============================] - 66s 75ms/step - loss: 0.1209 - accuracy: 0.9648 - val_loss: 0.1232 - val_accuracy: 0.9545\n",
      "Epoch 3/20\n",
      "880/880 [==============================] - 69s 79ms/step - loss: 0.0675 - accuracy: 0.9795 - val_loss: 0.1321 - val_accuracy: 0.9591\n",
      "Epoch 4/20\n",
      "880/880 [==============================] - 65s 74ms/step - loss: 0.0382 - accuracy: 0.9875 - val_loss: 0.3242 - val_accuracy: 0.9273\n",
      "Epoch 5/20\n",
      "880/880 [==============================] - 58s 66ms/step - loss: 0.0377 - accuracy: 0.9841 - val_loss: 0.1491 - val_accuracy: 0.9545\n",
      "Epoch 6/20\n",
      "880/880 [==============================] - 62s 71ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.1937 - val_accuracy: 0.9591\n",
      "Epoch 7/20\n",
      "880/880 [==============================] - 62s 71ms/step - loss: 0.0269 - accuracy: 0.9898 - val_loss: 0.1147 - val_accuracy: 0.9682\n",
      "Epoch 8/20\n",
      "880/880 [==============================] - 63s 72ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.1210 - val_accuracy: 0.9682\n",
      "Epoch 9/20\n",
      "880/880 [==============================] - 64s 72ms/step - loss: 0.0083 - accuracy: 0.9966 - val_loss: 0.1221 - val_accuracy: 0.9682\n",
      "Epoch 10/20\n",
      "880/880 [==============================] - 64s 73ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.1333 - val_accuracy: 0.9682\n",
      "Epoch 11/20\n",
      "880/880 [==============================] - 66s 75ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9636\n",
      "Epoch 12/20\n",
      "880/880 [==============================] - 72s 82ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1619 - val_accuracy: 0.9682\n",
      "Epoch 13/20\n",
      "880/880 [==============================] - 65s 74ms/step - loss: 8.4813e-04 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9636\n",
      "Epoch 14/20\n",
      "880/880 [==============================] - 65s 74ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.1301 - val_accuracy: 0.9682\n",
      "Epoch 15/20\n",
      "880/880 [==============================] - 65s 74ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.1855 - val_accuracy: 0.9636\n",
      "Epoch 16/20\n",
      "880/880 [==============================] - 66s 75ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.1411 - val_accuracy: 0.9682\n",
      "Epoch 17/20\n",
      "880/880 [==============================] - 65s 74ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.2270 - val_accuracy: 0.9636\n",
      "Epoch 18/20\n",
      "880/880 [==============================] - 67s 76ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1501 - val_accuracy: 0.9591\n",
      "Epoch 19/20\n",
      "880/880 [==============================] - 70s 80ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1705 - val_accuracy: 0.9591\n",
      "Epoch 20/20\n",
      "880/880 [==============================] - 74s 84ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "history=model.fit(trainX,trainY,epochs=20,callbacks=[checkpoint],validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('modelok.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0:'No Mask, NOT SAFE!',1:'Mask On, Good work!'}\n",
    "color = {0:(0,0,255), 1:(255,0,0)}\n",
    "\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'ADV1')\n",
    "#out = cv2.VideoWriter('lol.mp4', fourcc, 25, (640,480))\n",
    "while webcam.isOpened():\n",
    "    _, frame = webcam.read()\n",
    "    frame = cv2.flip(frame, 1, 1)\n",
    "    faces = classifier.detectMultiScale(frame, 1.1, 4)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        #cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 3)\n",
    "        face_data = frame[y:y+h, x:x+w]\n",
    "        resize_data = cv2.resize(face_data, (150,150))\n",
    "        resize_data = resize_data/255.0\n",
    "        final_data = np.expand_dims(resize_data, axis = 0)\n",
    "        prediction = model.predict(final_data)\n",
    "        \n",
    "        binary_answer = np.argmax(prediction,axis=1)[0]\n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), color[binary_answer], 3)\n",
    "        cv2.rectangle(frame, (x,y-40), (x+w, y), color[binary_answer], -1)\n",
    "        cv2.putText(frame, labels[binary_answer], (x,y-10), cv2.FONT_HERSHEY_PLAIN, 1, (255,255,255), 1)\n",
    "    \n",
    "    cv2.imshow(\"COVID-19 MASK\", frame)\n",
    "    #out.write(frame)\n",
    "        \n",
    "    if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "#out.release()\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
